# 100% Open-Source GPU Configuration
PORT=3003

# Local GPU Services (no cloud dependencies)
OLLAMA_URL=http://localhost:11434
COQUI_TTS_SERVER=http://localhost:5002
FASTER_WHISPER_SERVER=http://localhost:8001

# Model Configuration
OLLAMA_MODEL=llama3.1:8b
COQUI_MODEL=tts_models/en/ljspeech/tacotron2-DDC
COQUI_VOCODER=vocoder_models/en/ljspeech/hifigan_v2
WHISPER_MODEL=base.en

# Performance Settings
CUDA_VISIBLE_DEVICES=0
TORCH_CUDNN_V8_API_ENABLED=1
BATCH_SIZE=1
MAX_CONCURRENT=2

# Test Mode - Force 100% open source
TEST_MODE_ENABLED=true
FORCE_OPEN_SOURCE=true
DISABLE_CLOUD_FALLBACK=false  # Keep fallback for reliability

# Audio Settings
AUDIO_FORMAT=wav
SAMPLE_RATE=22050
AUDIO_DIR=/home/corey/voice-ai/audio-gpu

# Logging
LOG_LEVEL=info
ENABLE_PERFORMANCE_METRICS=true