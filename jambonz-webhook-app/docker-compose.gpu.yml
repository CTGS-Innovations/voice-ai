services:
  # Faster-Whisper - 100% Free GPU STT
  faster-whisper:
    image: onerahmet/openai-whisper-asr-webservice:latest-gpu
    container_name: faster-whisper-gpu
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - ASR_MODEL=base
      - ASR_ENGINE=faster_whisper
    ports:
      - "9000:9000"
    networks:
      - gpu-network

  # Coqui TTS - Production XTTS v2 (Human-like Speech Quality)
  coqui-tts:
    image: ghcr.io/coqui-ai/tts
    container_name: coqui-xtts-gpu
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - CUDA_VISIBLE_DEVICES=0
      # Auto-accept XTTS v2 license for non-commercial use
      - TTS_AGREE_LICENSE=1
    volumes:
      - coqui-models:/root/.local/share/tts
    ports:
      - "5002:5002"
    networks:
      - gpu-network
    # Use high-quality VITS model as recommended by Context7 research  
    entrypoint: ["python3", "TTS/server/server.py", "--model_name", "tts_models/en/vctk/vits", "--use_cuda", "true", "--port", "5002"]

  # Ollama - Local LLM
  ollama:
    image: ollama/ollama:latest
    container_name: ollama-gpu
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - OLLAMA_HOST=0.0.0.0
    volumes:
      - ollama-data:/root/.ollama
    ports:
      - "11435:11434"
    networks:
      - gpu-network

  # Main Webhook App with GPU support
  gpu-webhook-app:
    build:
      context: .
      dockerfile: Dockerfile.gpu
    container_name: jambonz-gpu-webhook
    restart: unless-stopped
    depends_on:
      - ollama
      - faster-whisper
      - coqui-tts
    environment:
      - PORT=3003
      - NODE_ENV=production
      - OLLAMA_URL=http://ollama:11434
      - OLLAMA_MODEL=llama3.1:8b
      - FASTER_WHISPER_URL=http://faster-whisper:9000
      - COQUI_TTS_URL=http://coqui-tts:5002
      # Remove paid API keys to force 100% open-source
      # - OPENAI_API_KEY=${OPENAI_API_KEY}
      # - ELEVENLABS_API_KEY=${ELEVENLABS_API_KEY}
      # - ELEVENLABS_VOICE_ID=${ELEVENLABS_VOICE_ID}
    volumes:
      - ./:/app
      - ./audio-gpu:/app/audio-gpu
    ports:
      - "3003:3003"
    working_dir: /app
    command: node open-source.js
    networks:
      - gpu-network

networks:
  gpu-network:
    driver: bridge

volumes:
  ollama-data:
  whisper-models:
  coqui-models: